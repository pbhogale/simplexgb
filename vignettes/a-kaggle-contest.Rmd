---
title: "Advanced regression"
author: "Prasanna Bhogale"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Advanced regression}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(tidyverse)
library(simplexgb)
library(janitor)
```

This vignette will use data from the [house prices kaggle contest](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview). This vignette will focus on thge simplest possible data cleaning and rely on the sensible defaults in `simplexgb` to construct a submission and evaluate the results on kaggle. For a more comprehensive data exploration of this data set check [this kernel](https://www.kaggle.com/erikbruin/house-prices-lasso-xgboost-and-a-detailed-eda)

**Get the data**

If you have the kaggle api, use `kaggle competitions download -c house-prices-advanced-regression-techniques` to obtain the data. See [this blog](https://adityashrm21.github.io/Setting-Up-Kaggle/) to see how to setup the kaggle api, if you want to.

we use [this kernel](https://www.kaggle.com/jimthompson/ensemble-model-stacked-model-example) to limit the features we use.

```{r}
CONFIRMED_ATTR_TRAIN <- c("MSSubClass","MSZoning","LotArea","LotShape","LandContour","Neighborhood",
                    "BldgType","HouseStyle","OverallQual","OverallCond","YearBuilt",
                    "YearRemodAdd","Exterior1st","Exterior2nd","MasVnrArea","ExterQual",
                    "Foundation","BsmtQual","BsmtCond","BsmtFinType1","BsmtFinSF1",
                    "BsmtFinType2","BsmtUnfSF","TotalBsmtSF","HeatingQC","CentralAir",
                    "1stFlrSF","2ndFlrSF","GrLivArea","BsmtFullBath","FullBath","HalfBath",
                    "BedroomAbvGr","KitchenAbvGr","KitchenQual","TotRmsAbvGrd","Functional",
                    "Fireplaces","FireplaceQu","GarageType","GarageYrBlt","GarageFinish",
                    "GarageCars","GarageArea","GarageQual","GarageCond","PavedDrive","WoodDeckSF",
                    "OpenPorchSF","Fence","SalePrice")
CONFIRMED_ATTR_TEST <- c("MSSubClass","MSZoning","LotArea","LotShape","LandContour","Neighborhood",
                    "BldgType","HouseStyle","OverallQual","OverallCond","YearBuilt",
                    "YearRemodAdd","Exterior1st","Exterior2nd","MasVnrArea","ExterQual",
                    "Foundation","BsmtQual","BsmtCond","BsmtFinType1","BsmtFinSF1",
                    "BsmtFinType2","BsmtUnfSF","TotalBsmtSF","HeatingQC","CentralAir",
                    "1stFlrSF","2ndFlrSF","GrLivArea","BsmtFullBath","FullBath","HalfBath",
                    "BedroomAbvGr","KitchenAbvGr","KitchenQual","TotRmsAbvGrd","Functional",
                    "Fireplaces","FireplaceQu","GarageType","GarageYrBlt","GarageFinish",
                    "GarageCars","GarageArea","GarageQual","GarageCond","PavedDrive","WoodDeckSF",
                    "OpenPorchSF","Fence")

TENTATIVE_ATTR <- c("Alley","LandSlope","Condition1","RoofStyle","MasVnrType","BsmtExposure",
                    "Electrical","EnclosedPorch","SaleCondition")

REJECTED_ATTR <- c("LotFrontage","Street","Utilities","LotConfig","Condition2","RoofMatl",
                   "ExterCond","BsmtFinSF2","Heating","LowQualFinSF","BsmtHalfBath",
                   "X3SsnPorch","ScreenPorch","PoolArea","PoolQC","MiscFeature","MiscVal",
                   "MoSold","YrSold","SaleType")

train_o <- read_csv("kaggle-house-prices/train.csv") 
train <- train_o[c(CONFIRMED_ATTR_TRAIN)] %>% clean_names()
train$sale_price <- log(train$sale_price)
test_o <- read_csv("kaggle-house-prices/test.csv") 
test <- test_o[c(CONFIRMED_ATTR_TEST)] %>% clean_names()
sample_sub <- read_csv("kaggle-house-prices/sample_submission.csv")
sample_sub %>% head()
```

#### Dealing with missing values

This data set has a lot of missing values. If we removed all rows which had a missing value of them, we would lost a significant amount of data. If the user does not want to deal with missing values (see the detailed analysis done for this data set [here](https://www.kaggle.com/erikbruin/house-prices-lasso-xgboost-and-a-detailed-eda)) `simplexgb` use a simple heuristic for dealing with missing values. For character variables, it use "not available" as a new level, while for numeric variables it generates random numbers from a normalized distribution of the available values of that variable. Clearly, there are better ways to impute missing values that include dependencies and correlations.. but this will suffice for now.

#### Preparing the training structure

```{r}
train_struct <- prepare_training_set(df = train, target_variable = "sale_price")
```


#### Cross validation

**Guessing the hyperparameters**

```{r}
hyp <- guess_hyperparameters(train_structure = train_struct)
hyp %>% print()
```

**Cross validation**

```{r}
cv_results <- cross_validate_xgb(train_structure = train_struct, hyperparameters = hyp, nfold = 5)
print(cv_results$metric)
```

It is not really clear what that means, but let us see how we perform if we make a submission.

**Training a model**

```{r}
hyp <- guess_hyperparameters(train_structure = train_struct)
print(hyp)
xgbmodel <- train_model_xgb(train_structure = train_struct, hyperparameters = hyp)
```

**Predicting on the test set**

```{r}
pred_df <- get_predictions_xgb(xgbmodel, test_df = test)
pred_df$sale_price <- exp(pred_df$sale_price)
pred_df %>% head()
```

**Constructing the submission**

```{r}
submission <- sample_sub
submission$Id <- test_id
submission %>% write_csv("kaggle-house-prices/submission_basic.csv")
```

We see that while `simplexgb` will get you from start to submission in no time at all, there is no short cut to understanding the data and careful cleaning and feature engineering. See [this kernel](https://www.kaggle.com/raimohaikari/house-prices-pls) for another example. 


## Linear model

```{r}
model_struct <- train_linear_model(train_structure = train_struct, model_structure = xgbmodel, hyperparameters = hyp)
pred_df <- get_predictions_linear(model_struct, test_df = test) %>% abs()
pred_df$sale_price <- exp(pred_df$sale_price)
pred_df %>% head()
submission <- sample_sub
submission$Id <- test_id
submission %>% write_csv("kaggle-house-prices/submission_linear.csv")
```

## RF model

```{r}
model_struct <- train_rf_model(train_structure = train_struct, model_structure = model_struct, hyperparameters = hyp)
spred_rf <- get_predictions_rf(model_structure = model_struct, test_df = test)
pred_rf$sale_price <- exp(pred_rf$sale_price)
pred_rf %>% head()
submission <- sample_sub
submission$Id <- test_id
submission %>% write_csv("kaggle-house-prices/submission_rf.csv")
```


Avg of these

```{r}
lin_pred <- read_csv("kaggle-house-prices/submission_linear.csv")
xgb_pred <- read_csv("kaggle-house-prices/submission_basic.csv")
rf_pred <- read_csv("kaggle-house-prices/submission_rf.csv")
pred <- tibble(Id = lin_pred$Id, SalePrice = (abs(lin_pred$SalePrice) + abs(xgb_pred$SalePrice) + abs(rf_pred$SalePrice)))
pred %>% write_csv("kaggle-house-prices/submission_average.csv")
```

